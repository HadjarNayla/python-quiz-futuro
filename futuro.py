import streamlit as st
import pandas as pd
import numpy as np
import io
import matplotlib.pyplot as plt
from io import BytesIO

# ----------------------------
# ğŸ·ï¸ APP CONFIGURATION
# ----------------------------
st.set_page_config(page_title="ğŸ¼ Pandas from 0 to Hero | Futuro School", layout="wide")

# ----------------------------
# ğŸ“ HEADER & BRANDING
# ----------------------------
st.title("ğŸ¼ Learn All Pandas Functions â€” From 0 to Hero")
st.write("This app teaches **Pandas** step by step using your dataset. Upload a CSV file and explore every important function interactively!")
st.write("Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù„Ù… **Pandas** Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§ØªÙƒ. Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù CSV ÙˆØ§Ø³ØªÙƒØ´Ù ÙƒÙ„ ÙˆØ¸ÙŠÙØ© Ù…Ù‡Ù…Ø© Ø¨Ø´ÙƒÙ„ ØªÙØ§Ø¹Ù„ÙŠ!")
st.markdown("### ğŸ“ **Futuro School** | Created by Teacher **Hadjar Nayla**")
st.markdown("---")

# ----------------------------
# ğŸ“‚ UPLOAD DATASET
# ----------------------------
st.header("ğŸ“ Step 1: Upload a CSV file | Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£ÙˆÙ„Ù‰: ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù CSV")
uploaded_file = st.file_uploader("Upload a CSV file", type=["csv"])

# helper: safe head for large dfs
def safe_head(df, n=5):
    try:
        return df.head(n)
    except Exception:
        return df.iloc[:n, :]

def df_to_excel_bytes(df):
    buffer = BytesIO()
    with pd.ExcelWriter(buffer, engine="xlsxwriter") as writer:
        df.to_excel(writer, index=False)
        writer.save()
    return buffer.getvalue()

if uploaded_file:
    try:
        df = pd.read_csv(uploaded_file)
    except Exception:
        # try with different encodings or separators
        try:
            uploaded_file.seek(0)
            df = pd.read_csv(uploaded_file, encoding='utf-8', sep=None, engine='python')
        except Exception as e:
            st.error(f"Failed to read CSV: {e}")
            st.stop()

    st.success("âœ… Dataset loaded successfully! | ØªÙ… ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
    st.dataframe(safe_head(df, 5))

    # ----------------------------
    # ğŸ“˜ BASIC FUNCTIONS
    # ----------------------------
    st.header("ğŸ“˜ Basic Pandas Functions | Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©")

    with st.expander("ğŸ”¹ df.head() â€” View first rows | Ø¹Ø±Ø¶ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£ÙˆÙ„Ù‰"):
        st.code("df.head()", language="python")
        st.write(safe_head(df, 5))
        st.write("Shows the first 5 rows of the DataFrame. | ÙŠØ¹Ø±Ø¶ Ø£ÙˆÙ„ 5 ØµÙÙˆÙ Ù…Ù† Ø¥Ø·Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")

    with st.expander("ğŸ”¹ df.tail() â€” View last rows | Ø¹Ø±Ø¶ Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ø£Ø®ÙŠØ±Ø©"):
        st.code("df.tail()", language="python")
        st.write(df.tail(5))
        st.write("Shows the last 5 rows of the DataFrame. | ÙŠØ¹Ø±Ø¶ Ø¢Ø®Ø± 5 ØµÙÙˆÙ Ù…Ù† Ø¥Ø·Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.")

    with st.expander("ğŸ”¹ df.shape â€” Get rows and columns count | Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ ÙˆØ§Ù„Ø£Ø¹Ù…Ø¯Ø©"):
        st.code("df.shape", language="python")
        st.write(df.shape)
        st.write("Returns (rows, columns). | ÙŠØ¹ÙŠØ¯ (Ø§Ù„ØµÙÙˆÙØŒ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©).")

    with st.expander("ğŸ”¹ df.columns â€” List all columns | Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©"):
        st.code("df.columns", language="python")
        st.write(df.columns.tolist())
        st.write("Displays the names of all columns in your dataset. | ÙŠØ¹Ø±Ø¶ Ø£Ø³Ù…Ø§Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ.")

    with st.expander("ğŸ”¹ df.info() â€” Show data types and non-null counts | Ø¹Ø±Ø¶ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„ÙØ§Ø±ØºØ©"):
        st.code("df.info()", language="python")
        buffer = io.StringIO()
        df.info(buf=buffer)
        info_str = buffer.getvalue()
        st.text(info_str)
        st.write("Summary about columns, dtypes, and missing values. | Ù…Ù„Ø®Øµ Ø¹Ù† Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©.")

    with st.expander("ğŸ”¹ df.describe() â€” Statistical summary | Ù…Ù„Ø®Øµ Ø¥Ø­ØµØ§Ø¦ÙŠ"):
        st.code("df.describe()", language="python")
        st.write(df.describe(include='all').astype(str).head(20))
        st.write("Stats for numeric and object columns. | Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙˆØ§Ù„Ù†ØµÙŠØ©.")

    with st.expander("ğŸ”¹ df.dtypes â€” Data types of each column | Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø¹Ù…ÙˆØ¯"):
        st.code("df.dtypes", language="python")
        st.write(df.dtypes)
        st.write("Lists the data type of each column. | ÙŠØ³Ø±Ø¯ Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„ÙƒÙ„ Ø¹Ù…ÙˆØ¯.")

    with st.expander("ğŸ”¹ df.index â€” Index information | Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ÙÙ‡Ø±Ø³"):
        st.code("df.index", language="python")
        st.write(df.index)
        st.write("Gives the index (row labels). | ÙŠØ¹Ø·ÙŠ Ø§Ù„ÙÙ‡Ø±Ø³ (ØªØ³Ù…ÙŠØ§Øª Ø§Ù„ØµÙÙˆÙ).")

    with st.expander("ğŸ”¹ df.isnull() â€” Detect missing values | ÙƒØ´Ù Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"):
        st.code("df.isnull().sum()", language="python")
        st.write(df.isnull().sum())
        st.write("Shows count of missing values per column. | ÙŠØ¹Ø±Ø¶ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© ÙÙŠ ÙƒÙ„ Ø¹Ù…ÙˆØ¯.")

    # ----------------------------
    # ğŸ§¹ DATA CLEANING
    # ----------------------------
    st.header("ğŸ§¹ Data Cleaning Functions | ÙˆØ¸Ø§Ø¦Ù ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    with st.expander("ğŸ”¹ df.dropna() â€” Remove missing rows | Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"):
        st.code("df.dropna()", language="python")
        st.write(safe_head(df.dropna(), 5))
        st.write("Removes rows with any missing values. | ÙŠØ²ÙŠÙ„ Ø§Ù„ØµÙÙˆÙ Ø§Ù„ØªÙŠ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©.")

    with st.expander("ğŸ”¹ df.fillna() â€” Replace missing values | Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©"):
        st.code("df.fillna(value)", language="python")
        fill_value = st.text_input("Fill missing values with (e.g., 0 or 'unknown'):", "0")
        try:
            # try numeric
            fv = float(fill_value)
        except Exception:
            fv = fill_value
        st.write(safe_head(df.fillna(fv), 5))
        st.write("Replaces missing values with given value. | ÙŠØ³ØªØ¨Ø¯Ù„ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø·Ø§Ø©.")

    with st.expander("ğŸ”¹ df.rename() â€” Rename columns | Ø¥Ø¹Ø§Ø¯Ø© ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©"):
        st.code("df.rename(columns={'OldName':'NewName'})", language="python")
        col_old = st.selectbox("Select column to rename:", df.columns, key="rename_old")
        col_new = st.text_input("New name:", f"{col_old}_renamed", key="rename_new")
        if st.button("Rename column"):
            df = df.rename(columns={col_old: col_new})
            st.success(f"Renamed {col_old} -> {col_new}")
            st.write(df.columns.tolist())

    with st.expander("ğŸ”¹ df.drop() â€” Remove columns or rows | Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø£Ùˆ Ø§Ù„ØµÙÙˆÙ"):
        st.code("df.drop('ColumnName', axis=1)", language="python")
        to_drop = st.multiselect("Select columns to drop (preview only):", df.columns)
        if to_drop:
            st.write(safe_head(df.drop(columns=to_drop), 5))
        else:
            st.write("No column selected.")

    with st.expander("ğŸ”¹ df.duplicated() & df.drop_duplicates() â€” Remove duplicates | Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª"):
        st.code("df.drop_duplicates()", language="python")
        st.write("Number of duplicate rows:", int(df.duplicated().sum()))
        st.write(safe_head(df.drop_duplicates(), 5))

    # ----------------------------
    # ğŸ” FILTERING & SELECTION
    # ----------------------------
    st.header("ğŸ” Filtering and Selection | Ø§Ù„ØªØµÙÙŠØ© ÙˆØ§Ù„Ø§Ø®ØªÙŠØ§Ø±")

    with st.expander("ğŸ”¹ Select one column | Ø§Ø®ØªÙŠØ§Ø± Ø¹Ù…ÙˆØ¯ ÙˆØ§Ø­Ø¯"):
        st.code("df['ColumnName']", language="python")
        column = st.selectbox("Select a column to view:", df.columns, key="single_col")
        st.write(safe_head(df[[column]], 5))

    with st.expander("ğŸ”¹ Select multiple columns | Ø§Ø®ØªÙŠØ§Ø± Ø£Ø¹Ù…Ø¯Ø© Ù…ØªØ¹Ø¯Ø¯Ø©"):
        st.code("df[['Col1', 'Col2']]", language="python")
        cols = st.multiselect("Choose columns:", df.columns, key="multi_cols")
        if cols:
            st.write(safe_head(df[cols], 5))
        else:
            st.write("No columns selected.")

    with st.expander("ğŸ”¹ Filter rows with condition | ØªØµÙÙŠØ© Ø§Ù„ØµÙÙˆÙ Ø¨Ø´Ø±Ø·"):
        st.code("df[df['Goals'] > 10]", language="python")
        cond_col = st.selectbox("Column to filter by (must be numeric):", [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])], key="filter_col")
        op = st.selectbox("Operator:", [">", "<", ">=", "<=", "==", "!="], key="filter_op")
        value = st.text_input("Value to compare:", "0", key="filter_val")
        try:
            val = float(value)
            if op == ">":
                out = df[df[cond_col] > val]
            elif op == "<":
                out = df[df[cond_col] < val]
            elif op == ">=":
                out = df[df[cond_col] >= val]
            elif op == "<=":
                out = df[df[cond_col] <= val]
            elif op == "==":
                out = df[df[cond_col] == val]
            else:
                out = df[df[cond_col] != val]
            st.write(safe_head(out, 10))
            st.write(f"Filtered rows: {len(out)}")
        except Exception as e:
            st.write("Could not apply filter:", e)

    with st.expander("ğŸ”¹ iloc and loc â€” Index selection | Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙÙ‡Ø±Ø³"):
        st.code("df.iloc[0:5, 0:3]  # by index\ndf.loc[0:5, ['Name','Club']]", language="python")
        rstart = st.number_input("Row start (iloc):", min_value=0, max_value=max(0, len(df)-1), value=0, key="iloc_rs")
        rend = st.number_input("Row end (iloc):", min_value=0, max_value=max(0, len(df)), value=min(5, len(df)), key="iloc_re")
        cstart = st.number_input("Col start index (iloc):", min_value=0, max_value=max(0, len(df.columns)-1), value=0, key="iloc_cs")
        cend = st.number_input("Col end index (iloc):", min_value=0, max_value=max(0, len(df.columns)), value=min(3, len(df.columns)), key="iloc_ce")
        try:
            st.write(safe_head(df.iloc[rstart:rend, cstart:cend], 10))
        except Exception as e:
            st.write("iloc selection failed:", e)
        st.write("You can also use df.loc with labels if your index is labeled.")

    # ----------------------------
    # ğŸ“ˆ SORTING & GROUPING
    # ----------------------------
    st.header("ğŸ“ˆ Sorting and Grouping | Ø§Ù„ØªØ±ØªÙŠØ¨ ÙˆØ§Ù„ØªØ¬Ù…ÙŠØ¹")

    with st.expander("ğŸ”¹ Sort by column | Ø§Ù„ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø¹Ù…ÙˆØ¯"):
        st.code("df.sort_values(by='Goals', ascending=False)", language="python")
        sort_col = st.selectbox("Select column to sort by:", df.columns, key="sort_col")
        asc = st.checkbox("Ascending?", value=False, key="sort_asc")
        try:
            st.write(safe_head(df.sort_values(by=sort_col, ascending=asc), 10))
        except Exception as e:
            st.write("Sort failed:", e)

    with st.expander("ğŸ”¹ Group by and aggregate | Ø§Ù„ØªØ¬Ù…ÙŠØ¹ ÙˆØ§Ù„ØªØ¬Ù…ÙŠØ¹"):
        st.code("df.groupby('Club').mean()", language="python")
        col_group = st.selectbox("Select a column to group by:", df.columns, key="group_col")
        try:
            grouped = df.groupby(col_group).mean(numeric_only=True)
            st.write(safe_head(grouped, 10))
        except Exception as e:
            st.write("Grouping failed:", e)

    with st.expander("ğŸ”¹ df.value_counts() â€” Count unique values | Ø¹Ø¯ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ÙØ±ÙŠØ¯Ø©"):
        st.code("df['ColumnName'].value_counts()", language="python")
        col_val = st.selectbox("Select a column for value counts:", df.columns, key="value_counts_2")
        try:
            st.write(df[col_val].value_counts().head(50))
        except Exception as e:
            st.write("Value counts failed:", e)

    # ----------------------------
    # ğŸ§® ADVANCED FUNCTIONS
    # ----------------------------
    st.header("ğŸ§® Advanced Pandas Functions | Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")

    with st.expander("ğŸ”¹ df.apply() â€” Apply custom functions | ØªØ·Ø¨ÙŠÙ‚ ÙˆØ¸Ø§Ø¦Ù Ù…Ø®ØµØµØ©"):
        st.code("df['Goals'].apply(lambda x: x * 2)", language="python")
        apply_col = st.selectbox("Column to apply function to (numeric):", [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])], key="apply_col")
        if st.button("Apply x2 to selected column"):
            try:
                df[f"{apply_col}_x2"] = df[apply_col].apply(lambda x: x * 2)
                st.write(safe_head(df[[apply_col, f"{apply_col}_x2"]], 10))
                st.success("Applied function and added new column.")
            except Exception as e:
                st.error(f"Apply failed: {e}")

    with st.expander("ğŸ”¹ df.merge() â€” Combine two datasets | Ø¯Ù…Ø¬ Ù…Ø¬Ù…ÙˆØ¹ØªÙŠ Ø¨ÙŠØ§Ù†Ø§Øª"):
        st.code("pd.merge(df1, df2, on='ID')", language="python")
        st.write("To demo merge upload a second CSV (optional). | Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¯Ù…Ø¬ Ø­Ù…Ù‘Ù„ Ù…Ù„Ù CSV Ø«Ø§Ù†Ù (Ø§Ø®ØªÙŠØ§Ø±ÙŠ).")
        uploaded_file2 = st.file_uploader("Upload second CSV to merge (optional)", type=["csv"], key="merge2")
        if uploaded_file2:
            try:
                df2 = pd.read_csv(uploaded_file2)
                common = list(set(df.columns).intersection(df2.columns))
                st.write("Common columns:", common)
                if common:
                    merge_on = st.selectbox("Select merge key:", common, key="merge_on")
                    how = st.selectbox("How to merge:", ["inner", "left", "right", "outer"], key="merge_how")
                    merged = pd.merge(df, df2, on=merge_on, how=how)
                    st.write("Merged result preview:")
                    st.write(safe_head(merged, 10))
                else:
                    st.write("No common columns to merge on.")
            except Exception as e:
                st.write("Failed to read/merge second file:", e)

    with st.expander("ğŸ”¹ df.concat() â€” Stack datasets together | ØªÙƒØ¯ÙŠØ³ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹Ù‹Ø§"):
        st.code("pd.concat([df1, df2])", language="python")
        st.write("Concatenate vertically or horizontally by uploading another file (optional).")
        uploaded_file3 = st.file_uploader("Upload CSV to concat (optional)", type=["csv"], key="concat2")
        if uploaded_file3:
            try:
                df3 = pd.read_csv(uploaded_file3)
                axis = st.radio("Axis:", (0, 1), key="concat_axis")
                conc = pd.concat([df, df3], axis=axis, ignore_index=(axis==0))
                st.write(safe_head(conc, 10))
            except Exception as e:
                st.write("Concat failed:", e)

    with st.expander("ğŸ”¹ df.pivot_table() â€” Create summary tables | Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ø¯Ø§ÙˆÙ„ Ù…Ù„Ø®ØµØ©"):
        st.code("pd.pivot_table(df, values='Goals', index='Club', aggfunc='mean')", language="python")
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        if numeric_cols:
            val = st.selectbox("Values (numeric):", numeric_cols, key="pivot_val")
            idx = st.selectbox("Index (categorical):", df.columns.tolist(), key="pivot_idx")
            agg = st.selectbox("Aggfunc:", ["mean", "sum", "count", "median"], key="pivot_agg")
            try:
                pt = pd.pivot_table(df, values=val, index=idx, aggfunc=agg)
                st.write(safe_head(pt, 20))
            except Exception as e:
                st.write("Pivot failed:", e)
        else:
            st.write("No numeric columns available for pivot_table.")

    # ----------------------------
    # ğŸ’¾ SAVE RESULTS
    # ----------------------------
    st.header("ğŸ’¾ Save and Export Data | Ø­ÙØ¸ ÙˆØªØµØ¯ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    with st.expander("ğŸ”¹ Save to CSV | Ø§Ù„Ø­ÙØ¸ ÙƒÙ…Ù„Ù CSV"):
        st.code("df.to_csv('output.csv', index=False)", language="python")
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("â¬‡ï¸ Download CSV", csv, "cleaned_data.csv", "text/csv")
        st.write("Exports DataFrame to CSV format. | ÙŠØµØ¯Ø± Ø¥Ø·Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ CSV.")

    with st.expander("ğŸ”¹ Save to Excel | Ø§Ù„Ø­ÙØ¸ ÙƒÙ…Ù„Ù Excel"):
        st.code("df.to_excel('output.xlsx', index=False)", language="python")
        xlsx_bytes = df_to_excel_bytes(df)
        st.download_button("â¬‡ï¸ Download Excel", xlsx_bytes, "cleaned_data.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.write("Exports DataFrame to Excel format. | ÙŠØµØ¯Ø± Ø¥Ø·Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Excel.")

    # ----------------------------
    # âš™ï¸ INDEX OPERATIONS
    # ----------------------------
    st.header("âš™ï¸ Index Operations | Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ÙÙ‡Ø±Ø³")

    with st.expander("ğŸ”¹ df.set_index() & df.reset_index()"):
        st.code("df.set_index('ID', inplace=True)\ndf.reset_index(inplace=True)", language="python")
        index_col = st.selectbox("Choose column to set as index (or None):", ["<none>"] + df.columns.tolist(), key="set_index")
        if index_col != "<none>":
            try:
                df_indexed = df.set_index(index_col)
                st.write("Indexed preview:")
                st.write(safe_head(df_indexed, 5))
            except Exception as e:
                st.write("Setting index failed:", e)
        else:
            st.write("No index change chosen.")

    with st.expander("ğŸ”¹ df.reindex() â€” Reindex DataFrame"):
        st.code("df.reindex(range(0, 10))", language="python")
        st.write("This will reindex â€” preview of first rows only.")
        try:
            st.write(safe_head(df.reindex(range(0, min(10, len(df)))), 10))
        except Exception as e:
            st.write("Reindex failed:", e)

    # ----------------------------
    # ğŸ” CONDITIONAL OPERATIONS
    # ----------------------------
    st.header("ğŸ” Conditional Operations | Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø´Ø±Ø·ÙŠØ©")

    with st.expander("ğŸ”¹ np.where & df.apply with condition"):
        st.code("df['Status'] = np.where(df['Age'] > 18, 'Adult', 'Minor')", language="python")
        numeric_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
        if numeric_cols:
            cond_col2 = st.selectbox("Choose numeric column for condition:", numeric_cols, key="cond_col2")
            val = st.number_input("Threshold value:", value=0.0, key="cond_val")
            new_col_name = st.text_input("New column name:", f"{cond_col2}_flag", key="cond_newname")
            if st.button("Create conditional column"):
                try:
                    df[new_col_name] = np.where(df[cond_col2] > val, "Yes", "No")
                    st.write(safe_head(df[[cond_col2, new_col_name]], 10))
                except Exception as e:
                    st.write("Conditional creation failed:", e)
        else:
            st.write("No numeric columns available.")

    # ----------------------------
    # ğŸ§© MULTIINDEX
    # ----------------------------
    st.header("ğŸ§© MultiIndex (Hierarchical Indexing) | Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ù‡Ø±Ù…ÙŠ")

    with st.expander("ğŸ”¹ Set MultiIndex & access"):
        st.code("df = df.set_index(['Region','Year'])", language="python")
        if len(df.columns) >= 2:
            mi_cols = st.multiselect("Choose 2 columns to set as MultiIndex (preview only):", df.columns, max_selections=2, key="mi_cols")
            if len(mi_cols) == 2:
                try:
                    df_mi = df.set_index(mi_cols)
                    st.write("MultiIndex preview:")
                    st.write(safe_head(df_mi, 10))
                except Exception as e:
                    st.write("MultiIndex failed:", e)
            else:
                st.write("Choose exactly 2 columns to demo MultiIndex.")
        else:
            st.write("Not enough columns for MultiIndex demo.")

    # ----------------------------
    # ğŸªœ ADVANCED GROUPBY
    # ----------------------------
    st.header("ğŸªœ Advanced GroupBy Operations | ØªØ¬Ù…ÙŠØ¹ Ù…ØªÙ‚Ø¯Ù…")

    with st.expander("ğŸ”¹ groupby with custom agg and filter"):
        st.code("grouped = df.groupby('Dept').agg({'Salary':['mean','max'],'Age':'median'})", language="python")
        group_cols = st.multiselect("Group by columns:", df.columns, key="adv_group_cols")
        if group_cols:
            try:
                agg_map = {}
                numeric = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]
                for nc in numeric[:3]:
                    agg_map[nc] = ['mean', 'max', 'count']
                grouped = df.groupby(group_cols).agg(agg_map)
                st.write(safe_head(grouped, 20))
            except Exception as e:
                st.write("Advanced groupby failed:", e)
        else:
            st.write("Choose columns to group by to see example.")

    # ----------------------------
    # ğŸ“ˆ ROLLING & WINDOWS
    # ----------------------------
    st.header("ğŸ“ˆ Rolling, Expanding, & EWM | Ø¯ÙˆØ§Ù„ Ø§Ù„Ù†ÙˆØ§ÙØ°")

    with st.expander("ğŸ”¹ rolling & expanding"):
        st.code("df['rolling_mean'] = df['Value'].rolling(window=3).mean()", language="python")
        if numeric_cols:
            win_col = st.selectbox("Choose numeric column for rolling:", numeric_cols, key="rolling_col")
            window = st.number_input("Window size:", min_value=1, max_value=100, value=3, key="rolling_window")
            try:
                df[f"{win_col}_rolling_mean"] = df[win_col].rolling(window=window).mean()
                st.write(safe_head(df[[win_col, f"{win_col}_rolling_mean"]], 10))
            except Exception as e:
                st.write("Rolling failed:", e)
        else:
            st.write("No numeric columns for rolling demo.")

    with st.expander("ğŸ”¹ ewm (exponential moving average)"):
        st.code("df['ewm_mean'] = df['Value'].ewm(alpha=0.5).mean()", language="python")
        if numeric_cols:
            ewm_col = st.selectbox("Choose column for EWM:", numeric_cols, key="ewm_col")
            span = st.number_input("Span (int):", min_value=1, max_value=100, value=5, key="ewm_span")
            try:
                df[f"{ewm_col}_ewm"] = df[ewm_col].ewm(span=span, adjust=False).mean()
                st.write(safe_head(df[[ewm_col, f"{ewm_col}_ewm"]], 10))
            except Exception as e:
                st.write("EWM failed:", e)
        else:
            st.write("No numeric columns for EWM demo.")

    # ----------------------------
    # âœï¸ STRING & TEXT OPERATIONS
    # ----------------------------
    st.header("âœï¸ String & Text Operations | Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù†ØµÙˆØµ")

    with st.expander("ğŸ”¹ Common .str methods"):
        st.code("df['Name'].str.lower()", language="python")
        text_cols = [c for c in df.columns if pd.api.types.is_object_dtype(df[c]) or pd.api.types.is_string_dtype(df[c])]
        if text_cols:
            text_col = st.selectbox("Choose text column:", text_cols, key="text_col")
            op = st.selectbox("Operation:", ["lower", "upper", "title", "strip", "contains", "split"], key="text_op")
            if op == "lower":
                st.write(safe_head(df[text_col].str.lower(), 10))
            elif op == "upper":
                st.write(safe_head(df[text_col].str.upper(), 10))
            elif op == "title":
                st.write(safe_head(df[text_col].str.title(), 10))
            elif op == "strip":
                st.write(safe_head(df[text_col].str.strip(), 10))
            elif op == "contains":
                pat = st.text_input("Substring / regex to search for:", "", key="contains_pat")
                try:
                    st.write(safe_head(df[text_col].str.contains(pat, na=False), 10))
                except Exception as e:
                    st.write("Contains search failed:", e)
            elif op == "split":
                sep = st.text_input("Separator (default whitespace):", " ", key="split_sep")
                try:
                    st.write(safe_head(df[text_col].str.split(sep).astype(str), 10))
                except Exception as e:
                    st.write("Split failed:", e)
        else:
            st.write("No text columns detected.")

    # ----------------------------
    # ğŸ•“ TIME SERIES OPERATIONS
    # ----------------------------
    st.header("ğŸ•“ Time Series Operations | Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©")

    with st.expander("ğŸ”¹ Convert to datetime & resample"):
        st.code("df['Date'] = pd.to_datetime(df['Date'])\ndf.set_index('Date', inplace=True)\ndf.resample('M').mean()", language="python")
        date_cols = [c for c in df.columns if pd.api.types.is_datetime64_any_dtype(df[c]) or df[c].astype(str).str.match(r'\d{4}[-/]\d{1,2}[-/]\d{1,2}').any()]
        # present available columns and let user convert
        st.write("Detected likely date-like columns (heuristic):", date_cols[:5])
        chosen_date_col = st.selectbox("Choose a column to convert to datetime (if any):", ["<none>"] + df.columns.tolist(), key="date_col")
        if chosen_date_col != "<none>":
            try:
                df[chosen_date_col] = pd.to_datetime(df[chosen_date_col], errors='coerce')
                st.write(df[chosen_date_col].dt.strftime('%Y-%m-%d').head(10))
                if st.checkbox("Set this column as index and resample monthly mean preview", key="resample_check"):
                    df_ts = df.set_index(chosen_date_col)
                    st.write(safe_head(df_ts.resample('M').mean(numeric_only=True), 10))
            except Exception as e:
                st.write("Datetime conversion failed:", e)
        else:
            st.write("No conversion chosen.")

    # ----------------------------
    # ğŸ§  LAMBDA & APPLYMAP
    # ----------------------------
    st.header("ğŸ§  Lambda & apply/applymap | Ø¯ÙˆØ§Ù„ Ù„Ø§Ù…Ø¨Ø¯Ø§ ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª")

    with st.expander("ğŸ”¹ df.applymap and df.apply"):
        st.code("df.applymap(lambda x: x.strip() if isinstance(x, str) else x)", language="python")
        if st.button("Trim whitespace in all object columns (preview)"):
            try:
                obj_cols = [c for c in df.columns if pd.api.types.is_object_dtype(df[c])]
                df_preview = df.copy()
                for c in obj_cols:
                    df_preview[c] = df_preview[c].apply(lambda x: x.strip() if isinstance(x, str) else x)
                st.write(safe_head(df_preview[obj_cols], 10))
            except Exception as e:
                st.write("applymap failed:", e)

    # ----------------------------
    # ğŸ§® CROSSTABS & PIVOT
    # ----------------------------
    st.header("ğŸ§® Crosstabs & Pivot | Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­ÙˆØ±ÙŠØ©")

    with st.expander("ğŸ”¹ pd.crosstab example"):
        st.code("pd.crosstab(df['Gender'], df['Dept'], margins=True)", language="python")
        if len(df.columns) >= 2:
            col_a = st.selectbox("Row (crosstab):", df.columns, key="ct_a")
            col_b = st.selectbox("Col (crosstab):", df.columns, key="ct_b")
            try:
                st.write(pd.crosstab(df[col_a], df[col_b], margins=True).head(50))
            except Exception as e:
                st.write("Crosstab failed:", e)
        else:
            st.write("Not enough columns for crosstab demo.")

    # ----------------------------
    # ğŸ§± COMBINING DATASETS (append/concat/merge)
    # ----------------------------
    st.header("ğŸ§± Combining Datasets | Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    with st.expander("ğŸ”¹ Append / concat / join examples"):
        st.code("pd.concat([df1, df2]); df.append(row); df.join(other_df)", language="python")
        st.write("Use concat to stack, join to combine by index, append is deprecated in newer pandas versions.")

    # ----------------------------
    # ğŸ“Š CORRELATION & COVARIANCE
    # ----------------------------
    st.header("ğŸ“Š Correlation & Covariance | Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· ÙˆØ§Ù„ØªØºØ§ÙŠØ±")

    with st.expander("ğŸ”¹ df.corr() and df.cov()"):
        st.code("df.corr(); df.cov()", language="python")
        try:
            corr = df.corr()
            st.write(safe_head(corr, 20))
            st.write("You can visualize the correlation matrix using a heatmap externally.")
        except Exception as e:
            st.write("Correlation calculation failed:", e)

    # ----------------------------
    # ğŸ§° PERFORMANCE OPTIMIZATION
    # ----------------------------
    st.header("ğŸ§° Performance & Optimization | Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†")

    with st.expander("ğŸ”¹ memory_usage, astype('category'), sample"):
        st.code("df.memory_usage(deep=True); df.astype('category')", language="python")
        try:
            mem = df.memory_usage(deep=True)
            st.write(mem)
            if st.button("Convert object columns to category where appropriate (preview)"):
                df_preview = df.copy()
                for c in df_preview.columns:
                    if df_preview[c].nunique() < (len(df_preview) * 0.5) and df_preview[c].dtype == object:
                        df_preview[c] = df_preview[c].astype('category')
                st.write(safe_head(df_preview.dtypes, 50))
        except Exception as e:
            st.write("Performance ops failed:", e)

    # ----------------------------
    # ğŸ§¾ ADVANCED EXPORT OPTIONS
    # ----------------------------
    st.header("ğŸ§¾ Advanced Export Options | Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØµØ¯ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")

    with st.expander("ğŸ”¹ to_csv with encoding, to_json, to_pickle"):
        st.code("df.to_csv('file.csv', sep=';', encoding='utf-8')", language="python")
        st.write("Use `to_pickle` for faster local re-loads: df.to_pickle('data.pkl')")

    # ----------------------------
    # ğŸ§ª USEFUL SHORTCUTS (display options)
    # ----------------------------
    st.header("ğŸ§ª Useful Shortcuts | Ø§Ø®ØªØµØ§Ø±Ø§Øª Ù…ÙÙŠØ¯Ø©")

    with st.expander("ğŸ”¹ pd.set_option and styling"):
        st.code("pd.set_option('display.max_columns', None)", language="python")
        if st.button("Show all columns (temporary)"):
            pd.set_option('display.max_columns', None)
            st.write("Max columns display set to None (for this session).")
        st.write("You can style DataFrame for reports (df.style...).")

    # ----------------------------
    # 31-50: EXPERT LEVEL (merged into sections)
    # ----------------------------
    st.header("âš¡ Expert-Level Pandas (31-50) | Ù…Ø³ØªÙˆÙ‰ Ù…ØªÙ‚Ø¯Ù…")

    with st.expander("ğŸ”¹ Advanced merge & join tricks"):
        st.code("pd.merge(df1, df2, on=['id','year'], how='outer', suffixes=('_l','_r'))", language="python")
        st.write("You can merge on multiple keys, use suffixes, or merge by index.")

    with st.expander("ğŸ”¹ Map, replace, dictionary mapping"):
        st.code("df['Gender'] = df['Gender'].map({'M':'Male','F':'Female'})", language="python")
        if st.button("Example map first categorical-like column"):
            cat_candidates = [c for c in df.columns if df[c].nunique() < 50]
            if cat_candidates:
                c = cat_candidates[0]
                mapping_preview = {k: str(k) + "_mapped" for k in list(df[c].dropna().unique())[:10]}
                st.write("Preview mapping (example):", mapping_preview)
                st.write(safe_head(df[[c]], 10))
            else:
                st.write("No good categorical candidates for demo.")

    with st.expander("ğŸ”¹ Math & logical operations"):
        st.code("df['Normalized'] = (df['Value'] - min)/(max-min)", language="python")
        st.write("Normalization, log transforms, boolean masks â€” use numpy functions (np.log, np.where).")

    with st.expander("ğŸ”¹ Time series resampling & shifting"):
        st.code("df.shift(1); df['diff'] = df['Value'].diff()", language="python")
        st.write("Shift and diff are handy for time-based features.")

    with st.expander("ğŸ”¹ Styling DataFrames for reports"):
        st.code("df.style.background_gradient()", language="python")
        st.write("Styling is great for HTML/Excel reports; not all styles show in Streamlit.")

    with st.expander("ğŸ”¹ Multi-level aggregation example"):
        st.code("df.groupby(['Dept','Gender']).agg({'Salary':['mean','max'],'Age':'median'})", language="python")
        st.write("Use dict-of-lists to specify different aggregations per column.")

    with st.expander("ğŸ”¹ Reshaping (stack/unstack/melt/pivot)"):
        st.code("df.melt(id_vars=['Name'], var_name='Subject', value_name='Score')", language="python")
        st.write("Melt to long, pivot to wide, stack/unstack for index<->columns transformations.")

    with st.expander("ğŸ”¹ Numpy integration & math"):
        st.code("df['sqrt'] = np.sqrt(df['Value'])", language="python")
        st.write("Use NumPy for vectorized math: np.log, np.exp, np.where, np.random etc.")

    with st.expander("ğŸ”¹ sklearn integration (preprocessing)"):
        st.code("from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf[['A','B']] = scaler.fit_transform(df[['A','B']])", language="python")
        st.write("Scale numeric columns before ML. (scikit-learn needed in environment)")

    with st.expander("ğŸ”¹ Visualization with matplotlib"):
        st.code("df.groupby('Dept')['Salary'].mean().plot(kind='bar')", language="python")
        try:
            viz_col = st.selectbox("Choose a numeric column to histogram (expert):", [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])], key="viz_col")
            if st.button("Show histogram"):
                fig, ax = plt.subplots()
                df[viz_col].dropna().hist(ax=ax)
                ax.set_title(f"Histogram of {viz_col}")
                st.pyplot(fig)
        except Exception as e:
            st.write("Plot failed:", e)

    with st.expander("ğŸ”¹ Working with large datasets (chunks & dtypes)"):
        st.code("pd.read_csv('big.csv', chunksize=10000); dtype={'ID':'int32'}", language="python")
        st.write("Use chunksize to iterate and dtype argument to save memory when reading big files.")

    with st.expander("ğŸ”¹ Encoding & categorical handling"):
        st.code("pd.get_dummies(df, columns=['Gender'])", language="python")
        st.write("Use .astype('category') or pd.get_dummies for one-hot encoding.")

    with st.expander("ğŸ”¹ Outlier detection (IQR)"):
        st.code("iqr = q3 - q1; outliers = df[(df['Value'] < q1-1.5*iqr) | (df['Value'] > q3+1.5*iqr)]", language="python")
        st.write("IQR method for simple outlier detection.")

    with st.expander("ğŸ”¹ Correlation heatmap hint"):
        st.code("import seaborn as sns\nsns.heatmap(df.corr(), annot=True)", language="python")
        st.write("Seaborn heatmap is useful in notebooks; Streamlit can show matplotlib figs.")

    with st.expander("ğŸ”¹ Data transformations (log/scaling/rank)"):
        st.code("df['log_salary'] = np.log1p(df['Salary'])", language="python")
        st.write("log1p handles zero values safely; ranking via df['rank'] = df['Score'].rank().")

    with st.expander("ğŸ”¹ Window analytics (rolling std/mean)"):
        st.code("df['rolling_avg'] = df['Value'].rolling(5).mean()", language="python")
        st.write("Use rolling/ewm for time-series features.")

    with st.expander("ğŸ”¹ DataFrame compare/debug"):
        st.code("df.compare(df2); df.equals(df2)", language="python")
        st.write("Useful to check changes between versions of datasets.")

    with st.expander("ğŸ”¹ String normalization & regex cleaning"):
        st.code("df['Text'] = df['Text'].str.replace(r'[^A-Za-z0-9 ]','', regex=True)", language="python")
        st.write("Use regex to clean text columns (be careful with languages and characters).")

    with st.expander("ğŸ”¹ Save/load with pickle for speed"):
        st.code("df.to_pickle('dataset.pkl'); pd.read_pickle('dataset.pkl')", language="python")
        st.write("Pickle is fast for local workflows but not ideal for sharing.")

    with st.expander("ğŸ”¹ Debugging tools & pipe"):
        st.code("df.pipe(lambda x: x.head())", language="python")
        st.write("Use df.info(memory_usage='deep') and df.pipe() for chaining and debugging.")

    # ----------------------------
    # ğŸ§¾ FINAL NOTES & FOOTER
    # ----------------------------
    st.markdown("---")
    st.markdown("### ğŸ“ Futuro School - Excellence in Data Science Education")
    st.markdown("**Developed by Teacher Hadjar Nayla** | ØªÙ… ØªØ·ÙˆÙŠØ±Ù‡ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø­Ø¬Ø§Ø± Ù†Ø§ÙŠÙ„Ø©")
    st.markdown("*Empowering students with practical data analysis skills* | *ØªÙ…ÙƒÙŠÙ† Ø§Ù„Ø·Ù„Ø§Ø¨ Ø¨Ù…Ù‡Ø§Ø±Ø§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù…Ù„ÙŠØ©*")

else:
    st.info("ğŸ‘† Please upload a CSV file to start learning Pandas! | ÙŠØ±Ø¬Ù‰ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù CSV Ù„Ø¨Ø¯Ø¡ ØªØ¹Ù„Ù… Pandas!")
    st.markdown("---")
    st.markdown("### ğŸ“ Futuro School")
    st.markdown("**Created by Teacher Hadjar Nayla** | ØªÙ… Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø¹Ù„Ù…Ø© Ø­Ø¬Ø§Ø± Ù†Ø§ÙŠÙ„Ø©")
